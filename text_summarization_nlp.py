# -*- coding: utf-8 -*-
"""text summarization_NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xnQyZiAgb9IGySoOxAYSNlnY2xUoBlux
"""

text = """In a world often dominated by negativity, it's important to remember the power of kindness and compassion. Small acts of kindness have the ability to brighten someone's day, uplift spirits, and create a ripple effect of positivity that can spread far and wide. Whether it's a smile to a stranger, a helping hand to a friend in need, or a thoughtful gesture to a colleague, every act of kindness has the potential to make a difference in someone's life.Beyond individual actions, there is also immense power in collective efforts to create positive change. When communities come together to support one another, incredible things can happen. From grassroots initiatives to global movements, people are uniting to tackle pressing social and environmental issues, driving meaningful progress and inspiring hope for a better future.It's also important to recognize the strength that lies within each and every one of us. We all have the ability to make a positive impact, no matter how small our actions may seem. By tapping into our innate compassion and empathy, we can cultivate a culture of kindness and empathy that enriches our lives and those around us.So let's embrace the power of kindness, and strive to make the world a better place one small act at a time. Together, we can create a brighter, more compassionate future for all."""

len(text)

import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from string import punctuation

nlp = spacy.load('en_core_web_sm')

doc=nlp(text)

tokens = [token.text.lower() for token in doc
          if not token.is_stop and
          not token.is_punct and
          token.text !='\n']

tokens

tokens1=[]
stopwords=list(STOP_WORDS)
allowed_pos= ['ADJ','PROPN','VERB','NOUN']
for token in doc:
      if token.text in stopwords or token.text in punctuation:
        continue
      if token.pos_ in allowed_pos:
        tokens1.append(token.text)

tokens1

from collections import Counter
word_freq = Counter(tokens)

word_freq

max_freq = max(word_freq.values())
max_freq

for word in word_freq.keys():
    word_freq[word] = word_freq[word]/max_freq
word_freq

sent_token = [sent.text for sent in doc.sents]
sent_token

sent_score = {}
for sent in sent_token:
    for word in sent.split():
        if word.lower() in word_freq.keys():
            if sent not in sent_score.keys():
                sent_score[sent] = word_freq[word]
            else:
                sent_score[sent] +=word_freq[word]
        print(word)

sent_score

import pandas as pd
pd.DataFrame(list(sent_score.items()),columns=['Sentence','Score'])

# Install dependencies
!pip install spacy gradio
!python -m spacy download en_core_web_sm

import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from string import punctuation
from collections import Counter
from heapq import nlargest
import gradio as gr

# Load spacy model once
nlp = spacy.load("en_core_web_sm")

def summarize_text(text, num_sentences=3):
    # Tokenization
    doc = nlp(text)
    tokens = [token.text.lower() for token in doc
              if not token.is_stop and not token.is_punct and token.text != '\n']

    # Word frequency
    word_freq = Counter(tokens)
    if not word_freq:
        return "No valid words found in the text."

    max_freq = max(word_freq.values())
    for word in word_freq.keys():
        word_freq[word] = word_freq[word]/max_freq

    # Sentence scoring
    sent_token = [sent.text for sent in doc.sents]
    sent_score = {}
    for sent in sent_token:
        for word in sent.split():
            if word.lower() in word_freq.keys():
                if sent not in sent_score.keys():
                    sent_score[sent] = word_freq[word]
                else:
                    sent_score[sent] += word_freq[word]

    summarized_sentences = nlargest(num_sentences, sent_score, key=sent_score.get)
    return " ".join(summarized_sentences)

# Gradio interface
iface = gr.Interface(
    fn=summarize_text,
    inputs=[gr.Textbox(lines=10, placeholder="Enter text here..."),
            gr.Slider(1, 10, step=1, value=3, label="Number of sentences")],
    outputs="text",
    title="Text Summarizer",
    description="Enter text and select number of sentences for summarization."
)

iface.launch()

from transformers import pipeline

summarizer=pipeline("summarization",model='t5-base',tokenizer='t5-base',framework='pt')

text = """In a world often dominated by negativity, it's important to remember the power of kindness and compassion. Small acts of kindness have the ability to brighten someone's day, uplift spirits, and create a ripple effect of positivity that can spread far and wide. Whether it's a smile to a stranger, a helping hand to a friend in need, or a thoughtful gesture to a colleague, every act of kindness has the potential to make a difference in someone's life.Beyond individual actions, there is also immense power in collective efforts to create positive change. When communities come together to support one another, incredible things can happen. From grassroots initiatives to global movements, people are uniting to tackle pressing social and environmental issues, driving meaningful progress and inspiring hope for a better future.It's also important to recognize the strength that lies within each and every one of us. We all have the ability to make a positive impact, no matter how small our actions may seem. By tapping into our innate compassion and empathy, we can cultivate a culture of kindness and empathy that enriches our lives and those around us.So let's embrace the power of kindness, and strive to make the world a better place one small act at a time. Together, we can create a brighter, more compassionate future for all."""

summary = summarizer(text,max_length=100,min_length=10,do_sample=False)
summary

print(summary[0]['summary_text'])

# Install dependencies
!pip install transformers gradio

from transformers import pipeline
import gradio as gr

# Initialize the summarizer pipeline (T5-base)
summarizer = pipeline("summarization", model="t5-base", tokenizer="t5-base", framework="pt")

def summarize_text(text, max_length=100, min_length=30):
    if not text.strip():
        return "Please enter some text."
    summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)
    return summary[0]['summary_text']

# Gradio interface
iface = gr.Interface(
    fn=summarize_text,
    inputs=[
        gr.Textbox(lines=10, placeholder="Enter your text here..."),
        gr.Slider(30, 300, step=10, value=100, label="Max Length"),
        gr.Slider(5, 50, step=5, value=10, label="Min Length")
    ],
    outputs="text",
    title="Text Summarizer (T5-base)",
    description="Paste text and get a summarized version using Hugging Face Transformers."
)

iface.launch()